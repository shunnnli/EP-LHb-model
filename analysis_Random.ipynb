{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison using Random with different RNN sparsity value\n",
    "\n",
    "Shun Li, 03/07/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickle files and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from EPLHb import EPLHb, gd, adam, NeuronalData\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optinal: load pickle file\n",
    "date = '20240313'\n",
    "filename = 'results/Random/'+date+'/model_comparison_'+date+'.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)\n",
    "\n",
    "training_loss_summary, relearn_loss_summary = loaded_dict\n",
    "\n",
    "LHb_network = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "EP_LHb = ['random','dales-law']\n",
    "LHb_DAN = ['real','mixed','dales-law']\n",
    "update_methods = ['corelease','fixed-sign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy for each network\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(15, 10))\n",
    "\n",
    "for network in training_loss_summary:\n",
    "    # print(network)\n",
    "    mean_tloss = np.mean(training_loss_summary[network],axis=0)\n",
    "    sem_tloss = stats.sem(training_loss_summary[network])\n",
    "    mean_rloss = np.mean(relearn_loss_summary[network],axis=0)\n",
    "    sem_rloss = stats.sem(relearn_loss_summary[network])\n",
    "\n",
    "    x = np.linspace(1,mean_tloss.shape[0],num=mean_tloss.shape[0],dtype='int32')\n",
    "    axs[0,0].plot(mean_tloss, label=network)\n",
    "    axs[0,0].fill_between(x,mean_tloss+sem_tloss,mean_tloss-sem_tloss,alpha=0.2)\n",
    "    axs[0,0].set_xlabel('Trianing iteration')\n",
    "    axs[0,0].set_ylabel('Training loss')\n",
    "    # axs[0,0].legend()\n",
    "\n",
    "    axs[1,0].plot(mean_tloss, label=network)\n",
    "    axs[1,0].fill_between(x,mean_tloss+sem_tloss,mean_tloss-sem_tloss,alpha=0.2)\n",
    "    axs[1,0].set_xlabel('Trianing iteration')\n",
    "    axs[1,0].set_ylabel('Training loss')\n",
    "    axs[1,0].set_ylim([0, 0.4])\n",
    "    # axs[1,0].legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    x = np.linspace(1,mean_rloss.shape[0],num=mean_rloss.shape[0],dtype='int32')\n",
    "    axs[0,1].plot(mean_rloss, label=network)\n",
    "    axs[0,1].fill_between(x,mean_rloss+sem_rloss,mean_rloss-sem_rloss,alpha=0.2)\n",
    "    axs[0,1].set_xlabel('Trianing iteration')\n",
    "    axs[0,1].set_ylabel('Relearn loss')\n",
    "    # axs[0,1].legend()\n",
    "\n",
    "    axs[1,1].plot(mean_rloss, label=network)\n",
    "    axs[1,1].fill_between(x,mean_rloss+sem_rloss,mean_rloss-sem_rloss,alpha=0.2)\n",
    "    axs[1,1].set_xlabel('Trianing iteration')\n",
    "    axs[1,1].set_ylabel('Relearn loss')\n",
    "    axs[1,1].set_ylim([0, 0.4])\n",
    "    # axs[1,1].legend()\n",
    "\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 0), loc='lower center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tloss, mean_rloss = [],[]\n",
    "for network in training_loss_summary:\n",
    "    mean_tloss.append(np.mean(training_loss_summary[network],axis=1))\n",
    "for network in relearn_loss_summary:\n",
    "    mean_rloss.append(np.mean(relearn_loss_summary[network],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plots of different conditions\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(15, 8))\n",
    "label_rotation = 20\n",
    "\n",
    "# Sort loss\n",
    "sorted_idx = np.argsort(np.mean(mean_tloss,axis=1))\n",
    "mean_tloss_sorted = np.array(mean_tloss)[sorted_idx].T\n",
    "sorted_keys_loss = np.array(list(training_loss_summary.keys()))[sorted_idx]\n",
    "# Plot loss\n",
    "sns.violinplot(data=mean_tloss_sorted, ax=axs[0],saturation=0.5,linewidth=0)\n",
    "sns.stripplot(data=mean_tloss_sorted, ax=axs[0], s=10, alpha=0.5)\n",
    "axs[0].set_xticks(np.arange(len(sorted_keys_loss)))\n",
    "axs[0].set_xticklabels(sorted_keys_loss)\n",
    "axs[0].set_ylabel('Training loss')\n",
    "plt.setp(axs[0].get_xticklabels(), rotation=label_rotation, ha=\"right\",rotation_mode=\"anchor\")\n",
    "\n",
    "\n",
    "# Plot with zoomed in y-axis\n",
    "# Plot loss\n",
    "# axs[1].violinplot(mean_tloss_sorted)\n",
    "sns.violinplot(data=mean_tloss_sorted, ax=axs[1],saturation=0.5,linewidth=0)\n",
    "sns.stripplot(data=mean_tloss_sorted, ax=axs[1], s=10, alpha=0.5)\n",
    "axs[1].set_xticks(np.arange(len(sorted_keys_loss)))\n",
    "axs[1].set_xticklabels(sorted_keys_loss)\n",
    "axs[1].set_ylabel('Training loss')\n",
    "axs[1].set_ylim([0.02,0.08])\n",
    "plt.setp(axs[1].get_xticklabels(), rotation=label_rotation, ha=\"right\",rotation_mode=\"anchor\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plots of accurarcy\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(15, 8))\n",
    "label_rotation = 20\n",
    "\n",
    "# Sort accuracy \n",
    "sorted_idx = np.argsort(np.mean(mean_rloss,axis=1))\n",
    "mean_rloss_sorted = np.array(mean_rloss)[sorted_idx].T\n",
    "sorted_keys_rloss = np.array(list(relearn_loss_summary.keys()))[sorted_idx]\n",
    "# Plot accuracy\n",
    "sns.violinplot(data=mean_rloss_sorted, ax=axs[0],saturation=0.5,linewidth=0)\n",
    "sns.stripplot(data=mean_rloss_sorted, ax=axs[0], s=10, alpha=0.5)\n",
    "axs[0].set_xticks(np.arange(len(sorted_keys_rloss)))\n",
    "axs[0].set_xticklabels(sorted_keys_rloss)\n",
    "axs[0].set_ylabel('Relearn loss')\n",
    "plt.setp(axs[0].get_xticklabels(), rotation=label_rotation, ha=\"right\",rotation_mode=\"anchor\")\n",
    "\n",
    "# Plot accuracy\n",
    "sns.violinplot(data=mean_rloss_sorted, ax=axs[1],saturation=0.5,linewidth=0)\n",
    "sns.stripplot(data=mean_rloss_sorted, ax=axs[1], s=10, alpha=0.5)\n",
    "axs[1].set_xticks(np.arange(len(sorted_keys_rloss)))\n",
    "axs[1].set_xticklabels(sorted_keys_rloss)\n",
    "axs[1].set_ylabel('Relearn loss')\n",
    "axs[1].set_ylim([0.02,0.08])\n",
    "plt.setp(axs[1].get_xticklabels(), rotation=label_rotation, ha=\"right\",rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN sparsity vs performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN sparsity vs training loss\n",
    "fig, axs = plt.subplots(1,1,figsize=(15, 8))\n",
    "\n",
    "for eplhb in EP_LHb:\n",
    "    for lhbdan in LHb_DAN:\n",
    "        for update in update_methods:\n",
    "            networks = [network for network in training_loss_summary if eplhb in network and lhbdan in network and update in network]\n",
    "            mean_tloss_sparse, sem_tloss_sparse = [],[]\n",
    "            for network in networks:\n",
    "                mean_tloss_sparse.append(np.mean(mean_tloss[network],axis=0))\n",
    "                sem_tloss_sparse.append(stats.sem(sem_tloss[network]))\n",
    "\n",
    "            # Plot mean and sem\n",
    "            mean_tloss_sparse = np.array(mean_tloss_sparse)\n",
    "            sem_tloss_sparse = np.array(sem_tloss_sparse)\n",
    "            x = LHb_network #np.linspace(1,mean_tloss_sparse.shape[1],num=mean_tloss_sparse.shape[1],dtype='int32')\n",
    "            axs.plot(np.mean(mean_tloss_sparse,axis=0), label=eplhb+'_'+lhbdan+'_'+update)\n",
    "            axs.fill_between(x,np.mean(mean_tloss_sparse,axis=0)+np.mean(sem_tloss_sparse,axis=0),np.mean(mean_tloss_sparse,axis=0)-np.mean(sem_tloss_sparse,axis=0),alpha=0.2)\n",
    "            axs.set_xlabel('LHb sparsity')\n",
    "            axs.set_ylabel('Training loss')\n",
    "            axs.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN sparsity vs relearn loss\n",
    "fig, axs = plt.subplots(1,1,figsize=(15, 8))\n",
    "\n",
    "for eplhb in EP_LHb:\n",
    "    for lhbdan in LHb_DAN:\n",
    "        for update in update_methods:\n",
    "            networks = [network for network in relearn_loss_summary if eplhb in network and lhbdan in network and update in network]\n",
    "            mean_rloss_sparse, sem_rloss_sparse = [],[]\n",
    "            for network in networks:\n",
    "                mean_rloss_sparse.append(np.mean(mean_rloss[network],axis=0))\n",
    "                sem_rloss_sparse.append(stats.sem(sem_rloss[network]))\n",
    "\n",
    "            # Plot mean and sem\n",
    "            mean_rloss_sparse = np.array(mean_rloss_sparse)\n",
    "            sem_rloss_sparse = np.array(sem_rloss_sparse)\n",
    "            x = LHb_network\n",
    "            axs.plot(np.mean(mean_rloss_sparse,axis=0), label=eplhb+'_'+lhbdan+'_'+update)\n",
    "            axs.fill_between(x,np.mean(mean_rloss_sparse,axis=0)+np.mean(sem_rloss_sparse,axis=0),np.mean(mean_rloss_sparse,axis=0)-np.mean(sem_rloss_sparse,axis=0),alpha=0.2)\n",
    "            axs.set_xlabel('LHb sparsity')\n",
    "            axs.set_ylabel('Relearn loss')\n",
    "            axs.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps between different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmaps to plot differences between conditions\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(15, 10))\n",
    "\n",
    "conditions = [LHb_network, EP_LHb, LHb_DAN, update_methods]\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    # Choose network that satisfies condition\n",
    "    cond_1 = condition[0]\n",
    "    cond_1_networks = [network for network in training_loss_summary if cond_1 in network.split('_')[i]]\n",
    "    cond_2 = condition[1:]\n",
    "    cond_2_networks = [network for network in training_loss_summary if any(c in network.split('_')[i] for c in cond_2)]\n",
    "\n",
    "    x = np.array(np.mean([np.mean(training_loss_summary[network],axis=1) for network in cond_1_networks],axis=1)).squeeze()\n",
    "    y = np.array(np.mean([np.mean(training_loss_summary[network],axis=1) for network in cond_2_networks],axis=1)).squeeze()\n",
    "\n",
    "    x_reshape = x[:,np.newaxis]\n",
    "    y_reshape = y[np.newaxis,:]\n",
    "    diff = x_reshape - y_reshape\n",
    "\n",
    "    # Plot heatmap\n",
    "    im = axs[i//2,i%2].imshow(diff, cmap='PRGn',vmax=abs(diff).max(), vmin=-abs(diff).max())\n",
    "    axs[i//2,i%2].set_xticks(np.arange(len(cond_2_networks)))\n",
    "    axs[i//2,i%2].set_yticks(np.arange(len(cond_1_networks)))\n",
    "    axs[i//2,i%2].set_xticklabels(cond_2_networks)\n",
    "    axs[i//2,i%2].set_yticklabels(cond_1_networks)\n",
    "    axs[i//2,i%2].set_xlabel(cond_2)\n",
    "    axs[i//2,i%2].set_ylabel(cond_1)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(axs[i//2,i%2].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Set colorbar\n",
    "    cbar = axs[i//2,i%2].figure.colorbar(im, ax=axs[i//2,i%2])\n",
    "    cbar.ax.set_ylabel('Difference', rotation=-90, va=\"bottom\")\n",
    "    # Set title\n",
    "    axs[i//2,i%2].set_title('Training loss: '+cond_1+' - '+'/'.join(cond_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmaps to plot differences between conditions\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(15, 10))\n",
    "\n",
    "conditions = [LHb_network, EP_LHb, LHb_DAN, update_methods]\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    # Choose network that satisfies condition\n",
    "    cond_1 = condition[0]\n",
    "    cond_1_networks = [network for network in training_loss_summary if cond_1 in network.split('_')[i]]\n",
    "    cond_2 = condition[1:]\n",
    "    cond_2_networks = [network for network in training_loss_summary if any(c in network.split('_')[i] for c in cond_2)]\n",
    "\n",
    "    x = np.array(np.mean([np.mean(relearn_loss_summary[network],axis=1) for network in cond_1_networks],axis=1)).squeeze()\n",
    "    y = np.array(np.mean([np.mean(relearn_loss_summary[network],axis=1) for network in cond_2_networks],axis=1)).squeeze()\n",
    "\n",
    "    x_reshape = x[:,np.newaxis]\n",
    "    y_reshape = y[np.newaxis,:]\n",
    "    diff = x_reshape - y_reshape\n",
    "\n",
    "    # Plot heatmap\n",
    "    im = axs[i//2,i%2].imshow(diff, cmap='PRGn',vmax=abs(diff).max(), vmin=-abs(diff).max())\n",
    "    axs[i//2,i%2].set_xticks(np.arange(len(cond_2_networks)))\n",
    "    axs[i//2,i%2].set_yticks(np.arange(len(cond_1_networks)))\n",
    "    axs[i//2,i%2].set_xticklabels(cond_2_networks)\n",
    "    axs[i//2,i%2].set_yticklabels(cond_1_networks)\n",
    "    axs[i//2,i%2].set_xlabel(cond_2)\n",
    "    axs[i//2,i%2].set_ylabel(cond_1)\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(axs[i//2,i%2].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Set colorbar\n",
    "    cbar = axs[i//2,i%2].figure.colorbar(im, ax=axs[i//2,i%2])\n",
    "    cbar.ax.set_ylabel('Difference', rotation=-90, va=\"bottom\")\n",
    "    # Set title\n",
    "    axs[i//2,i%2].set_title('Relearn loss: '+cond_1+' - '+'/'.join(cond_2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
